---
title: "Projet de MRR"
author: "Elena BOUCHAUD, Hanna BEN JEDIDIA et Aymeric MARBOEUF"
date: "7 janvier 2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

Nous disposons d'un jeu de données comprenant des informations sur le poids et des paramètres susceptibles d'aider à déterminer le poinds d'une personnes tel que la taille, le tour des hanches... À l'aide de ce jeu de données, nous souhaitons trouver un modèle qui détermine le poids d'une personne en fonction des différentes variables.

À l'origine, ce jeu de données est composé de 252 observations et de 19 variables: ID de la personnes, le pourcentage de graisse corporelle selon l'équation de Brozek, le pourcentage de graisse corporelle selon l'équation de Siri, la densité, l'age, le poids, la taille, l'indice d'adiposité, le poids sans gras, la circonférence du cou, la circonférence de la poitrine, la circonférence de l'abdomaine, la circonférence des hanche, la circonférence des cuisses, la circonférence des genou, la circonférence des chevilles, la circonférence du biceps, la circonférence de l'avant bras et la circonférence du poignée.

```{r echo = FALSE, message = FALSE}
library(MASS)
library(corrplot)
library(glmnet)
library(hydroGOF)
library(class)

tab = data.frame(read.table("FA.dat", sep = "", header = TRUE))
boxplot(tab)
```

## Analyse est nétoyage des données

La première colonne, l'ID de la personne, ne donne pas d'information sur le poids elle est présente à titre indicatif. Il est donc préférable de supprimer cette colonne pour avoir une bonne modelisation.
Les cas 48, 76 et 96 ont des erreurs les données de pourcentage de gras. Nous allons donc supprimer ces lignes pour ne pas corrompre nos données. Le cas 182 a un pourcentage de gras négatif se qui n'est pas possible, nous supprimons cette ligne également. D'après l'analyse des données la taille du cas 42 est éronné mais peut être corrigée.

```{r echo = FALSE}
tab = tab[-c(48, 76, 96,182),-1]
tab$Height[42] = 69.5
```

En analysant un peu plus les données, nous remarquons qu'il y a deux valeurs parmi le poids qui semblent abérante ou qui apratiennent à des cas de grandes obésités et qui peut corrompre nos modèles. Une valeur aussi parmi le poids sans gras semble abérante (108kg) ainsi que deux autres parmi la circonférence de la poitrine. Les lignes contenant ces valeurs seront aussi enlevées.

```{r echo = FALSE}
m = which(grepl(max(tab$Weight),tab$Weight))
tab = tab[-c(m),]
m = which(grepl(max(tab$Weight),tab$Weight))
tab = tab[-c(m),]
m = which(grepl(max(tab$Fat_Free_Weight),tab$Fat_Free_Weight))
tab = tab[-c(m),]
m = which(grepl(max(tab$Chest_circumference),tab$Chest_circumference))
tab = tab[-c(m),]
m = which(grepl(max(tab$Chest_circumference),tab$Chest_circumference))
tab = tab[-c(m),]
boxplot(tab)
```

Nous allons donc travailler avec un jeu de données contenant 243 observations et 18 variables.

## Corrélations entre les données

```{r echo = FALSE}
corrplot(cor(tab))
```
Nous observons que les variables sont fortement corélées entre elles. Or il n'est pas possible d'utiliser d'effectuer une régression linéaire. Nous allons donc effectuer une régression par pénalisation.

```{r echo = FALSE}
n = dim(tab)[1]
tabSim = tab[setdiff(1:n,0:floor(n/5)),] 
tabTest = tab[0:floor(n/5),]
tabTest2 = tabTest[-5]
tabSim2= tabSim[-5]
Sim = as.matrix(data.frame(tabSim2))
```

## Setpwise, Forward et Backward

Nous pouvons utiliser des méthodes de sélections de variables tel que Stepwise, forward et backward.

```{r echo = FALSE}
lmModel = lm(Weight~., data = tab)
stepModel = stepAIC(lmModel, direction = "both", trace = FALSE)
forwardModel = stepAIC(lmModel, direction = "forward", trace = FALSE)
backwardModel = stepAIC(lmModel, direction = "backward", trace = FALSE)
```

Le adjusted R-squared de ces méthode est  \({R^2}_{adj} = 0.9931\). Le adjusted R-squared est proche de 1, donc ces méthodes sont efficaces pour la sélection de variables.

## Ridge



```{r echo = FALSE, warning= FALSE}
modridge2 = glmnet(Sim, tabSim$Weight, alpha=0, family="gaussian")
cvModridge2= cv.glmnet(Sim,y= tabSim$Weight, alpha=0)
bestLambdaRidge2 = cvModridge2$lambda.min
predictRidge = predict(modridge2, as.matrix(tabTest2),s=bestLambdaRidge2,type="class")
rmse(as.numeric(tabTest$Weight),as.numeric(predictRidge))
rmseRidge = sqrt(mean((tabTest$Weight-predictRidge)^2))
```

## CART

```{r echo = FALSE}
modtree=tree(spam~.,data=tabSim)
pred = predict(modtree,newdata = tabTest)
p = prediction(pred[,2],spam)
perf = performance(p,"tpr","fpr")
plot(perf)
```

## Bagging

```{r echo = FALSE}
modbag = bagging(spam~.,data=tabSim,coob=TRUE)
pred3 = predict(modbag,newdata = tabTest, type ="prob")
p2 = prediction(pred3[,2],spam)
perf2 = performance(p2,"tpr","fpr")
plot(perf2, col = "blue")
```

## Random Forest

```{r echo = FALSE}
modFor2 = randomForest(spam~.,data=tabSim)
pred4 = predict(modFor2,newdata = tabTest, type ="prob")
p3 = prediction(pred4[,2],spam)
perf3 = performance(p3,"tpr","fpr")
plot(perf3, col = "red")
```

## KNN
Nous allons utiliser une méthode d'apprentissage supervisé utilisé en machine learning. Celle-ci consiste à faire la moyenne des plus proches voisins d'une valeur à déterminer. Nous cherchons à minimiser la valeur du rmse et comparer cette valeur avec les autres modèles. On calcule donc les valeurs du rmse pour différentes valeurs de k afin de trouver le plus petit.

```{r echo = FALSE}
r = vector(length=500)
for(i in 1:500){
  knnModel = knn(train = tabSim2, test = tabTest2, cl = tabSim$Weight, k = i)
  m = tabSim$Weight-as.numeric(as.character(knnModel))
  rmseknn = sqrt(mean(m^2))
  r[i]=rmseknn
}
plot(r, xlab= "Valeur de k", ylab = "Valeur du RMSE", main = "Courbe du RMSE en fonction de k sans sélection de variables")
min(r)
which(grepl(min(r),r))
```

On observe que le k minimisant le RMSE se situe aux alentours de 100. Il faut donc prendre environ 100 voisins pour se rapprocher au mieux des valeurs réelles. Cependant, on obtient un  RMSE de 24 environ ce qui est une valeur très importante par rapport aux valeurs de la RMSE trouvés avec les autres modèles.
