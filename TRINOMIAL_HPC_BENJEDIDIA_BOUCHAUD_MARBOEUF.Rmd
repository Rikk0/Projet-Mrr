---
title: "Projet de MRR"
author: "Elena BOUCHAUD, Hanna BEN JEDIDIA et Aymeric MARBOEUF"
date: "7 janvier 2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

Nous disposons d'un jeu de données comprenant des informations sur le poids et des paramètres susceptibles d'aider à déterminer le poinds d'une personnes tel que la taille, le tour des hanches... À l'aide de ce jeu de données, nous souhaitons trouver un modèle qui détermine le poids d'une personne en fonction des différentes variables.

À l'origine, ce jeu de données est composé de 252 observations et de 19 variables: ID de la personnes, le pourcentage de graisse corporelle selon l'équation de Brozek, le pourcentage de graisse corporelle selon l'équation de Siri, la densité, l'age, le poids, la taille, l'indice d'adiposité, le poids sans gras, la circonférence du cou, la circonférence de la poitrine, la circonférence de l'abdomaine, la circonférence des hanche, la circonférence des cuisses, la circonférence des genou, la circonférence des chevilles, la circonférence du biceps, la circonférence de l'avant bras et la circonférence du poignée.

```{r echo = FALSE, message = FALSE}
library(MASS)
library(corrplot)
library(glmnet)
library(hydroGOF)
library(class)

tab = data.frame(read.table("FA.dat", sep = "", header = TRUE))
boxplot(tab)
```

## Analyse est nétoyage des données

La première colonne, l'ID de la personne, ne donne pas d'information sur le poids elle est présente à titre indicatif. Il est donc préférable de supprimer cette colonne pour avoir une bonne modelisation.
Les cas 48, 76 et 96 ont des erreurs les données de pourcentage de gras. Nous allons donc supprimer ces lignes pour ne pas corrompre nos données. Le cas 182 a un pourcentage de gras négatif se qui n'est pas possible, nous supprimons cette ligne également. D'après l'analyse des données la taille du cas 42 est éronné mais peut être corrigée.

```{r echo = FALSE}
tab = tab[-c(48, 76, 96,182),-1]
tab$Height[42] = 69.5
```

En analysant un peu plus les données, nous remarquons qu'il y a deux valeurs parmi le poids qui semblent abérante ou qui apratiennent à des cas de grandes obésités et qui peut corrompre nos modèles. Une valeur aussi parmi le poids sans gras semble abérante (108kg) ainsi que deux autres parmi la circonférence de la poitrine. Les lignes contenant ces valeurs seront aussi enlevées.

```{r echo = FALSE}
m = which(grepl(max(tab$Weight),tab$Weight))
tab = tab[-c(m),]
m = which(grepl(max(tab$Weight),tab$Weight))
tab = tab[-c(m),]
m = which(grepl(max(tab$Fat_Free_Weight),tab$Fat_Free_Weight))
tab = tab[-c(m),]
m = which(grepl(max(tab$Chest_circumference),tab$Chest_circumference))
tab = tab[-c(m),]
m = which(grepl(max(tab$Chest_circumference),tab$Chest_circumference))
tab = tab[-c(m),]
boxplot(tab)
```

Nous allons donc travailler avec un jeu de données contenant 243 observations et 18 variables.

## Corrélations entre les données

```{r echo = FALSE}
corrplot(cor(tab))
```
Nous observons que les variables sont fortement corélées entre elles. Or il n'est pas possible d'utiliser d'effectuer une régression linéaire. Nous allons donc effectuer une régression par pénalisation.

```{r echo = FALSE}
n = dim(tab)[1]
tabSim = tab[setdiff(1:n,0:floor(n/5)),] 
tabTest = tab[0:floor(n/5),]
tabTest2 = tabTest[-5]
tabSim2= tabSim[-5]
Sim = as.matrix(data.frame(tabSim2))
```

## Setpwise, Forward et Backward

Nous pouvons utiliser des méthodes de sélections de variables tel que Stepwise, forward et backward.

```{r echo = FALSE}
lmModel = lm(Weight~., data = tab)
stepModel = stepAIC(lmModel, direction = "both", trace = FALSE)
forwardModel = stepAIC(lmModel, direction = "forward", trace = FALSE)
backwardModel = stepAIC(lmModel, direction = "backward", trace = FALSE)
```

Le adjusted R-squared de ces méthode est  \({R^2}_{adj} = 0.9931\). Le adjusted R-squared est proche de 1, donc ces méthodes sont efficaces pour la sélection de variables.

## Ridge



```{r echo = FALSE, warning= FALSE}
modridge2 = glmnet(Sim, tabSim$Weight, alpha=0, family="gaussian")
cvModridge2= cv.glmnet(Sim,y= tabSim$Weight, alpha=0)
bestLambdaRidge2 = cvModridge2$lambda.min
predictRidge = predict(modridge2, as.matrix(tabTest2),s=bestLambdaRidge2,type="class")
rmse(as.numeric(tabTest$Weight),as.numeric(predictRidge))
rmseRidge = sqrt(mean((tabTest$Weight-predictRidge)^2))
```

## CART

```{r echo = FALSE}
modtree=tree(spam~.,data=tabSim)
pred = predict(modtree,newdata = tabTest)
p = prediction(pred[,2],spam)
perf = performance(p,"tpr","fpr")
plot(perf)
```

## Bagging

```{r echo = FALSE}
modbag = bagging(spam~.,data=tabSim,coob=TRUE)
pred3 = predict(modbag,newdata = tabTest, type ="prob")
p2 = prediction(pred3[,2],spam)
perf2 = performance(p2,"tpr","fpr")
plot(perf2, col = "blue")
```

## Random Forest

```{r echo = FALSE}
modFor2 = randomForest(spam~.,data=tabSim)
pred4 = predict(modFor2,newdata = tabTest, type ="prob")
p3 = prediction(pred4[,2],spam)
perf3 = performance(p3,"tpr","fpr")
plot(perf3, col = "red")
```

## Conclusion

Nous allons comparer toutes les courbes ROC:

```{r echo = FALSE}
plot(perf)
plot(perf2, add = TRUE, col = "blue")
plot(perf3, add = TRUE, col = "red")
plot(perf4, add = TRUE, col = "green")
plot(perf5, add = TRUE, col = "orange")
plot(perf6, add = TRUE, col = "brown")
plot(perf7, add = TRUE, col = "purple")
legend(0.6,0.8,legend=c("CART","Bagging", "Random Forest", "LDA", "QAD", "Logistic Regression", "Bayes"), col=c("black","blue","red","green","orange","brown","purple"),lty=1, cex=0.8, ncol=1)
```

Nous observons que la meilleure courbe est la courbe ROC de la machine Random Forest. Nous conseillons donc dans ce cas d'utiliser la méthode Random Forest afin de trier les spams de la boîte mail.
